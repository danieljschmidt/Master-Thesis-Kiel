\chapter{Introduction} % 3-4 pages ?

In order to set appropriate policies, both central banks and ministries need as precise information on the current and future economic conditions as possible. This is why macroeconomic forecasting is a very active field of research and central banks have hired many researchers specializing in forecasting. % TODO clumsy
However, predicting macroeconomic variables is not only an important but also a very challenging task. In the following, I provide a bird's eye view on the field, structured by the challenges that macroeconomic data poses to forecasters:\\

% TODO PART I
% TODO Macroeconomic forecasting in general

First of all, a large number of potential predictors is available to the economic forecaster. The FRED-MD database \citep{McCrackenNg2016}, for example, features more than 100 series at monthly frequency. Since most time series only span a few decades, having roughly as many observations as potential predictors is not a very unlikely scenario. Standard econometric models such as linear regressions and vector autoregressive models are not suitable forecast models for such ``wide'' datasets because they overfit and produce imprecise forecasts \citep{StockWatson2006}. Even for a medium-sized dataset of, say, 20-30 predictors, flexible models are likely to perform worse than more restrictive models. Common ways to deal with the curse of dimensionality are variable selection, shrinkage (towards a simple benchmark model), dimension reduction and combining the forecasts of smaller models.

Moreover, predictive relationships are often not stable over time. While there is often in-sample evidence that the parameters in a model are not constant, it has been difficult to exploit this knowledge in forecast models that take these instabilities explicitly into account - for example by allowing for several regimes of economic dynamics. To see why, note that the number of parameters in a model with $n$ different regimes is $n$ times higher than in a plain model with constant parameters. An alternative to discrete breaks is to allow for small changes in the parameters in every time step. Moreover, instead of attempting to model the parameter instability explicitly, a forecaster could also use ad-hoc approaches such as a rolling estimation windows or averaging across estimation windows.  See \citet{Rossi2013} for a survey on forecasting in the presence of instabilities.

Not only slope parameters may vary over time, also error variances might change. In that case allowing for stochastic volatility can improve forecast accuracy, especially for density forecasts \citep{Clark2011}.

Furthermore, some of the potential predictor variables are measured at a frequency that is different from the sampling frequency of the target variable: Most macroeconomic variables are measured annually, quarterly or monthly and financial data are typically available at a daily (or even higher) frequency. By aggregating the high-frequency data to a lower frequency, valuable information on the evolution of the target variable might get lost. The primary approaches to this problem are state space models and MIDAS regressions: In a state space model specified at some baseline frequency (e.g.~monthly), we can include a variable measured with a lower frequency (e.g.~quarterly) by writing it as a function of lags of its unobserved counterpart at the baseline frequency and inserting missing values whenever the variable is not measured.\footnote{
	The exact functional form of the frequency aggregation depends on whether the variable with lower sampling frequency is a stock or a flow variable and on what transformations have been applied to it. See section \ref{sec:mixed-frequency} for a more detailed treatment for the case of a log-differenced flow variable such as GDP growth.
} A MIDAS regression is a linear regression of a low-frequency (target) variable on a high-frequency (predictor) variable and its lags, quite similar to a distributed lag model. If the mismatch between the two sampling frequencies is very large, one might want to include a large number of lags of the high-frequency variable. In this case, restricting the coefficients of the lag polynomial to follow a certain functional form might improve forecast accuracy. If the mismatch is not that large, such as in the case of a quarterly left-hand side and a monthly right-hand side variable, an unrestricted MIDAS model may be more appropriate. For a more extensive survey of mixed-frequency models, see \citet{ForoniMarcellino2013}. Furthermore, \citet{BaiEtal2013} provide insights on the theoretical relationship between the state space and the MIDAS approach to mixed-frequency data.
	
\citeauthor{ForoniMarcellino2013} also discuss another challenge of forecasting macroeconomic time series, namely the so-called ``ragged edge'' of the data: Macroeconomic time series are typically not published immediately after the end of the reference period but with a delay of several days or weeks. Consequently, a suitable forecast model should be able to deal with missing observations for some time series at the end of the sample.

For variables like GDP that are measured at a lower frequency than its potential predictors, predicting its value in the current time period (and updating these predictions as new information on the predictors arrives) is as important as predicting its value in future time periods. Such predictions are referred to as nowcasts. If the variable has a long publication lag, even ``backcasts'' (e.g.~predictions of GDP in the past quarter) might be of interest. \citet{BanburaEtal2013} provide an overview over the field of nowcasting. Naturally, how to deal with different sampling frequencies and the ``ragged edge'' of the data matters even more for nowcasting than for (long-term) forecasting.

Finally, the target variable and/or predictor variables may be revised. This has important implications for the design of forecast experiments: In order to compare the performance of competing models in a realistic way, we should use a so-called real-time dataset that allows us to reconstruct the latest available vintage of data at a forecast origin. Moreover, if the target variable is revised, it is not clear which estimate of it to use for forecast evaluation - there are good argument for both early estimates and the latest available vintage. See \citet{Croushore2011} for a more detailed discussion of the role of revisions in economic forecasting.\\

% TODO PART II
% TODO Dynamic factor models

Dynamic factor models have emerged as one of the most popular forecast models because they provide a coherent framework to deal with many of the challenges in macroeconomic forecasting described above: They are suitable models for forecasting with many predictors by design because they model the common dynamics of variables with a much smaller number of unobserved variables, so-called factors. See \citet{StockWatson2002} for an early contribution that focuses on (long-term) forecasting based on a large dataset. Since dynamic factor models can be cast into state space form, they also provide an elegant way for dealing with missing values that may arise due to publication lags or the inclusion of variables with a lower sampling frequency. This feature of dynamic factor models is especially appreciated in the nowcasting literature \citep{GiannoneEtal2008, BanburaEtal2013} and in the closely related literature on constructing a coincident business cycle index \citep{MarianoMurasawa2003}.

The two main estimation approaches are principal components and maximum likelihood. Principal components-based estimation does not require strict parametric assumptions on the distribution of error terms and is therefore a more robust estimation procedure than maximum likelihood. However, if the error terms are indeed normally distributed, maximum likelihood estimation is more efficient. Furthermore, the EM-algorithm for maximum likelihood estimation of state space models can easily deal with missing values. This is why maximum likelihood estimation as studied in \citet{DozEtal2012} and \citet{BanburaModugno2014} is the state-of-the-art estimation technique for dynamic factor models that are used in macroeconomic forecasting and nowcasting \citep[for example, see][for a description of model of the Federal Reserve Bank of New York for nowcasting real GDP growth]{BokEtal2017}. \citet{StockWatson2011} provide a more detailed review of estimation methods for dynamic factor models.\\

% TODO PART III
% TODO Bayesian Dynamic factor models

Bayesian estimation of (mixed-frequency) dynamic factor models is not widespread in economic forecasting, although - being also likelihood-based method - it is as convenient as maximum likelihood estimation for dealing with missing values. The few exceptions in the literature are \citet{LucianiRicci2014}, \citet{DAgostinoEtal2016}, \citet{MarcellinoEtal2016} and \citet{AntolinDiazEtal2017}.

% Both \citet{LucianiRicci2014} and \citet{DAgostinoEtal2016} use a mixed-frequency dynamic factor model for nowcasting GDP growth. While the basic dynamic factor model for nowcasting only features the factor at the current time in the measurement equation, they generalize this model and also include lags of the factor in order to allow for heterogeneity in the dynamics of the variables. \citet{LucianiRicci2014} and \citet{DAgostinoEtal2016} argue that Bayesian shrinkage is particularly useful to deal with the resulting proliferation of parameters. In the respective empirical sections, \citet{LucianiRicci2014} nowcast Norwegian GDP growth and \citet{DAgostinoEtal2016} nowcast US GDP growth.

% The focus of \citet{MarcellinoEtal2016} is not on the ``dynamic heterogeneity'' of the variables but rather on allowing the disturbances for both the factor and idiosyncratic components to have time-varying disturbances. Due to the modular structure of a Gibbs sampler, this is most easily done within the framework of Bayesian statistics. \citet{MarcellinoEtal2016} report small gains in the accuracy of point forecasts and larger gains in the accuracy of density forecasts.

% \citet{AntolinDiazEtal2017} extend the Bayesian dynamic factor model of \citet{MarcellinoEtal2016} by allowing for a time-varying mean and apply it to a mixed-frequency dataset in order to describe the decline in long-run GDP growth in advanced economies. Although it is not the primary focus of their analysis, they also compare the accuracy of nowcasts generated by their model with the simpler alternatives and find that the inclusion of a time-varying mean improves the accuracies of nowcasts especially in the post-recession sample.\\

% TODO Part IV
% TODO My contribution

In this thesis, I contribute to the literature on forecasting with Bayesian mixed-frequency dynamic factor models in the following ways:

First of all, I study a problem with the Bayesian estimation of mixed-frequency dynamic factor models that has not been discussed in the previous literature and suggest an alternative model specification that avoids this problem.

Second, I consider the use of a sparse prior on the factor loadings as an alternative to [...]. Although sparse factor models have already been studied \citep{KaufmannSchumacher2017} %TODO add more sources
, I am not aware of any published article that employs a sparse dynamic factor model in macroeconomic forecastinga

Finally, I provide the first overview of this field of research. Despite the [only four published articles (to my best knowledge)], there seems to be the need for an overview because ... [differences in estimation procedure, different motivation for using the Bayesian framework, do not cite each other] Overview as we go

Following the previous literature, my focus is not on long-term forecasts but on short time horizons, including nowcasts and backcasts. Empirical section with GDP. Some parts general, but estimation procedure very specific to models for nowcasting GDP. \\

% TODO Part V
% TODO Outline

The thesis is structured as follows: Section \ref{sec:dfm} Section \ref{sec:bayes} Section \ref{sec:experiment} Section \ref{sec:conclusion} concludes.
